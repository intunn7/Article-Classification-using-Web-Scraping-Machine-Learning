# Article Classification using Web Scraping & Machine Learning ğŸ“ŠğŸ¤–

[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-completed-success.svg)]()

Sistem klasifikasi otomatis artikel ilmiah menggunakan web scraping dari Springer dan machine learning untuk mengkategorikan artikel ke dalam 5 topik: Audio Processing, Video Processing, Signal Processing, Image Processing, dan Text Processing.

![Project Banner](https://via.placeholder.com/800x200/4285f4/ffffff?text=Article+Classification+ML+Project)

---

## ğŸ“‹ Deskripsi Project

Project ini merupakan implementasi **end-to-end machine learning pipeline** yang mencakup:
1. **Web Scraping**: Mengumpulkan data artikel ilmiah dari Springer (2019-2024)
2. **Data Preprocessing**: Cleaning, tokenization, lemmatization
3. **Feature Engineering**: One-Hot Encoding, Bag-of-Words, TF-IDF
4. **Model Training**: Naive Bayes, SVM, Logistic Regression
5. **Evaluation**: Perbandingan performa model dengan berbagai metrik
6. **Visualization**: Analisis distribusi data dan hasil klasifikasi

### ğŸ¯ Tujuan Project
- Mengotomatisasi klasifikasi artikel ilmiah berdasarkan topik
- Membandingkan efektivitas berbagai teknik feature extraction
- Mengevaluasi performa algoritma machine learning untuk text classification
- Menganalisis tren publikasi artikel dalam 5 tahun terakhir (2019-2024)

---

## âœ¨ Fitur Utama

### ğŸ•·ï¸ Web Scraping
- **Sumber Data**: Springer Link (link.springer.com)
- **Periode**: 2019 - 2024
- **Sampling**: 0.1% dari total artikel per topik (proporsional)
- **Data Dikumpulkan**: 
  - Judul artikel
  - Tahun publikasi
  - Abstrak
  - Topik/kategori

### ğŸ”§ Data Preprocessing
- **Text Cleaning**: Remove punctuation, lowercase conversion
- **Tokenization**: Split text into words
- **Stopwords Removal**: Hapus kata-kata umum (English)
- **Lemmatization**: Normalisasi kata ke bentuk dasar

### ğŸ“Š Feature Engineering
Tiga metode ekstraksi fitur:
1. **One-Hot Encoding**: Binary presence/absence
2. **Bag-of-Words (BoW)**: Word frequency counting
3. **TF-IDF**: Term Frequency-Inverse Document Frequency

### ğŸ¤– Machine Learning Models
- **Naive Bayes** (MultinomialNB)
- **Support Vector Machine** (SVM - Linear Kernel)
- **Logistic Regression** (C=10, max_iter=100)

### ğŸ“ˆ Visualisasi & Analisis
- Distribusi artikel per topik
- Tren publikasi per tahun
- Word Cloud untuk setiap topik
- Confusion Matrix untuk evaluasi model
- Perbandingan akurasi model

---

## ğŸ› ï¸ Teknologi yang Digunakan

| Kategori | Library/Tool | Fungsi |
|----------|--------------|--------|
| **Core** | Python 3.9+ | Bahasa pemrograman |
| **Notebook** | Jupyter Notebook | Development environment |
| **Web Scraping** | BeautifulSoup | HTML parsing |
| | requests | HTTP requests |
| **Data Processing** | pandas | Data manipulation |
| | numpy | Numerical operations |
| **NLP** | NLTK | Natural language processing |
| | WordNetLemmatizer | Word lemmatization |
| **Feature Extraction** | CountVectorizer | BoW & One-Hot |
| | TfidfVectorizer | TF-IDF calculation |
| **Machine Learning** | scikit-learn | ML algorithms & metrics |
| | LogisticRegression | Classification model |
| | SVC (SVM) | Classification model |
| | MultinomialNB | Classification model |
| **Visualization** | matplotlib | Data visualization |
| | seaborn | Statistical plots |
| | WordCloud | Word cloud generation |
| **Model Persistence** | joblib | Save/load models |

---

## ğŸ“¦ Instalasi

### Persyaratan Sistem
- Python 3.9 atau lebih baru
- Jupyter Notebook / JupyterLab
- Koneksi internet (untuk web scraping)
- RAM minimum 4GB (recommended 8GB)

### Langkah Instalasi

#### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/yourusername/article-classification.git
cd article-classification
```

#### 2ï¸âƒ£ Buat Virtual Environment (Opsional tapi Disarankan)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

#### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

**Atau install manual:**
```bash
pip install pandas numpy requests beautifulsoup4 nltk matplotlib seaborn scikit-learn wordcloud joblib jupyter
```

#### 4ï¸âƒ£ Download NLTK Data
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
```

#### 5ï¸âƒ£ Jalankan Jupyter Notebook
```bash
jupyter notebook fixx.ipynb
```

---

## ğŸš€ Cara Menggunakan

### Pipeline Lengkap:

#### **Step 1: Web Scraping**
```python
# Jalankan cell scraping untuk mengumpulkan data
# Output: scraping_totalpages.csv
```
- Scrapes artikel dari 5 topik
- Sampling proporsional 0.1% per topik
- Menyimpan hasil ke CSV

#### **Step 2: Data Preprocessing**
```python
# Jalankan cell preprocessing
# Output: hasil_preprocessing.csv
```
- Cleaning text
- Tokenization & lemmatization
- Remove stopwords

#### **Step 3: Feature Engineering**
```python
# Jalankan cell feature engineering
```
- Membuat 3 representasi fitur:
  - One-Hot Encoding
  - Bag-of-Words
  - TF-IDF

#### **Step 4: Model Training & Evaluation**
```python
# Jalankan cell training
```
- Split data (80% train, 20% test)
- Train 3 model untuk setiap metode feature
- Total: 9 kombinasi model-feature

#### **Step 5: Analisis & Visualisasi**
```python
# Jalankan cell visualisasi
```
- Confusion matrix
- Akurasi comparison
- Word clouds
- Distribusi topik per tahun

---

## ğŸ“Š Dataset

### Topik yang Dikumpulkan:
1. **Audio Processing** (~22 artikel)
2. **Video Processing** (~61 artikel)
3. **Signal Processing** (~209 artikel)
4. **Image Processing** (~231 artikel)
5. **Text Processing** (~221 artikel)

### Struktur Data:
| Kolom | Deskripsi | Tipe |
|-------|-----------|------|
| Topik | Kategori artikel | String |
| Judul | Judul artikel | String |
| Tahun Terbit | Tahun publikasi (2019-2024) | Integer |
| Abstrak | Abstrak artikel | Text |
| Preprocessing Judul | Judul yang sudah di-preprocess | String |
| Preprocessing Abstrak | Abstrak yang sudah di-preprocess | Text |

### Sample Data:
```
Topik: Audio Processing
Judul: "A lightweight approach to real-time speaker diarization"
Tahun: 2024
Abstrak: "This manuscript deals with the task of real-time speaker diarization..."
```

---

## ğŸ¯ Hasil & Performa Model

### Model Comparison (Berdasarkan Akurasi)

| Feature Method | Naive Bayes | SVM | Logistic Regression |
|----------------|-------------|-----|---------------------|
| **One-Hot Encoding** | ~XX% | ~XX% | ~XX% |
| **Bag-of-Words** | ~XX% | ~XX% | ~XX% |
| **TF-IDF** | ~XX% | ~XX% | **~XX%** â­ |

*Note: Jalankan notebook untuk melihat hasil aktual*

### Key Findings:
- ğŸ† **Best Model**: [Model terbaik berdasarkan hasil]
- ğŸ“ˆ **Best Feature Method**: TF-IDF umumnya memberikan hasil terbaik
- ğŸ¯ **Average Accuracy**: ~XX%
- ğŸ“Š **Class Performance**: Image/Signal Processing cenderung lebih mudah diklasifikasi

---

## ğŸ“ˆ Visualisasi

### 1. Distribusi Artikel per Topik
Bar chart menampilkan jumlah artikel yang berhasil di-scrape untuk setiap topik.

### 2. Tren Publikasi per Tahun
Line plot menunjukkan perkembangan jumlah publikasi dari 2019-2024 untuk setiap topik.

### 3. Word Cloud per Topik
Visual representasi kata-kata paling sering muncul dalam setiap kategori topik.

### 4. Confusion Matrix
Heatmap yang menunjukkan performa prediksi model untuk setiap kelas.

### 5. Model Accuracy Comparison
Bar chart perbandingan akurasi antar model dan metode feature extraction.

---

## ğŸ”§ Konfigurasi & Parameter

### Web Scraping Parameters:
```python
SAMPLE_PERCENTAGE = 0.001  # 0.1% dari total artikel
ARTICLES_PER_PAGE = 20
DATE_RANGE = "2019-2024"
LANGUAGE = "En"
```

### Model Hyperparameters:

**Logistic Regression:**
```python
C = 10
max_iter = 100
random_state = 42
```

**SVM:**
```python
kernel = 'linear'
random_state = 42
```

**Naive Bayes:**
```python
# Default parameters
```

### Train-Test Split:
```python
test_size = 0.2
random_state = 42
```

---

## ğŸ“ Struktur Project

```
article-classification/
â”œâ”€â”€ fixx.ipynb                      # Main Jupyter notebook
â”œâ”€â”€ scraping_totalpages.csv         # Raw scraped data
â”œâ”€â”€ hasil_preprocessing.csv         # Preprocessed data
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Documentation (file ini)
â”œâ”€â”€ models/                         # Saved models (optional)
â”‚   â”œâ”€â”€ best_model_tfidf_lr.pkl
â”‚   â”œâ”€â”€ vectorizer_tfidf.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ visualizations/                 # Generated plots (optional)
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ wordcloud_*.png
â”‚   â””â”€â”€ distribution_*.png
â””â”€â”€ data/                          # Additional data (optional)
    â””â”€â”€ raw_articles.json
```

---

## ğŸ§ª Metodologi

### 1. Data Collection
- **Source**: Springer Link API/Web interface
- **Method**: BeautifulSoup HTML parsing
- **Sampling**: Stratified proportional sampling (0.1%)

### 2. Preprocessing Pipeline
```
Raw Text â†’ Lowercase â†’ Remove Punctuation â†’ Tokenize 
â†’ Remove Stopwords â†’ Lemmatization â†’ Clean Text
```

### 3. Feature Extraction
- **One-Hot**: Binary encoding kata unik
- **BoW**: Frequency count per kata
- **TF-IDF**: Weighted importance per kata

### 4. Model Training
- **Cross-validation**: 80-20 split
- **Evaluation Metrics**: 
  - Accuracy
  - Precision (per class)
  - Recall (per class)
  - F1-Score
  - Confusion Matrix

### 5. Model Selection
- Perbandingan 9 kombinasi (3 models Ã— 3 features)
- Pilih model dengan akurasi tertinggi
- Save model terbaik dengan joblib

---

## ğŸ’¡ Use Cases

### 1. ğŸ“š Digital Library Management
- Auto-tagging artikel ilmiah
- Kategorisasi otomatis paper baru
- Rekomendasi artikel serupa

### 2. ğŸ” Research Assistant
- Filtering artikel berdasarkan topik
- Literature review automation
- Trend analysis penelitian

### 3. ğŸ“Š Academic Analytics
- Analisis publikasi per bidang
- Identifikasi hot topics
- Research gap detection

### 4. ğŸ“ Educational Platform
- Kurasi konten pembelajaran
- Resource recommendation
- Topic clustering

---

## ğŸ› Troubleshooting

### Error: "HTTP 429 - Too Many Requests"
**Penyebab**: Springer membatasi request rate

**Solusi**:
```python
import time
time.sleep(2)  # Tambahkan delay antar request
```

### Error: "NLTK data not found"
**Solusi**:
```python
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
```

### Error: "Memory Error during vectorization"
**Penyebab**: Dataset terlalu besar untuk RAM

**Solusi**:
- Kurangi jumlah artikel
- Gunakan `max_features` parameter:
```python
vectorizer = TfidfVectorizer(max_features=5000)
```

### Warning: "Convergence Warning - LogisticRegression"
**Solusi**:
```python
LogisticRegression(max_iter=200)  # Increase iterations
```

### Scraping Returns Empty Data
**Penyebab**: Struktur HTML Springer berubah

**Solusi**:
- Inspect halaman web terbaru
- Update CSS selectors dalam kode scraping
- Gunakan browser developer tools untuk debugging

---

## ğŸš§ Roadmap & Future Improvements

### Version 2.0 (Planned)
- [ ] Deep Learning models (BERT, Transformer)
- [ ] Real-time classification API
- [ ] Support multi-language articles
- [ ] Automatic model retraining pipeline
- [ ] Web dashboard untuk visualisasi
- [ ] Integration dengan database (PostgreSQL/MongoDB)
- [ ] Citation network analysis
- [ ] Author collaboration network

### Enhancement Ideas
- [ ] Active learning untuk improve model
- [ ] Ensemble methods
- [ ] Feature importance analysis
- [ ] Hyperparameter tuning (GridSearch/RandomSearch)
- [ ] Cross-validation dengan K-Fold
- [ ] Export model ke ONNX untuk deployment

---

## ğŸ“Š Evaluation Metrics Explained

### Accuracy
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
Persentase prediksi yang benar dari total prediksi.

### Precision
```
Precision = TP / (TP + FP)
```
Dari yang diprediksi positif, berapa yang benar-benar positif?

### Recall
```
Recall = TP / (TP + FN)
```
Dari yang sebenarnya positif, berapa yang berhasil terdeteksi?

### F1-Score
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```
Harmonic mean dari precision dan recall.

### Confusion Matrix
Tabel yang menunjukkan:
- **True Positive (TP)**: Prediksi benar positif
- **True Negative (TN)**: Prediksi benar negatif
- **False Positive (FP)**: Prediksi salah positif
- **False Negative (FN)**: Prediksi salah negatif

---

## ğŸ‘¥ Tim Pengembang

Project ini dikembangkan oleh:

- **[Nama Anggota 1]** - Data Scientist & ML Engineer
- **[Nama Anggota 2]** - Web Scraping Specialist
- **[Nama Anggota 3]** - Data Analyst & Visualization
- **[Nama Anggota 4]** - Documentation & Testing

*Silakan update dengan informasi tim Anda*

---

## ğŸ¤ Kontribusi

Kontribusi sangat dihargai! Cara berkontribusi:

1. **Fork** repository ini
2. Buat **branch** fitur (`git checkout -b feature/AmazingFeature`)
3. **Commit** perubahan (`git commit -m 'Add some AmazingFeature'`)
4. **Push** ke branch (`git push origin feature/AmazingFeature`)
5. Buat **Pull Request**

### Contribution Guidelines:
- âœ… Gunakan PEP 8 style guide
- âœ… Tambahkan docstrings untuk fungsi baru
- âœ… Update README jika menambah fitur
- âœ… Test kode sebelum submit PR
- âœ… Sertakan komentar yang jelas

---

## ğŸ“„ Lisensi

Project ini dilisensikan under **MIT License**.

```
MIT License

Copyright (c) 2024 Article Classification Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software...
```

---

## ğŸ“§ Kontak & Support

Punya pertanyaan atau saran?

- ğŸ“§ Email: [your-email@example.com]
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/article-classification/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/article-classification/discussions)

---

## ğŸŒŸ Acknowledgments

Terima kasih kepada:
- **Springer Nature** untuk menyediakan akses artikel ilmiah
- **Scikit-learn Team** untuk machine learning library yang powerful
- **NLTK Team** untuk NLP tools
- **Python Community** untuk semua library yang luar biasa

---

## ğŸ“š References & Resources

### Papers & Articles:
- [Text Classification with Machine Learning](https://example.com)
- [TF-IDF Feature Extraction](https://example.com)
- [Naive Bayes for Text Classification](https://example.com)

### Documentation:
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [NLTK Documentation](https://www.nltk.org/)
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

### Tutorials:
- [Text Mining with Python](https://example.com)
- [Web Scraping Best Practices](https://example.com)

---

## ğŸ“ Citation

Jika Anda menggunakan project ini dalam penelitian, mohon cite:

```bibtex
@misc{article_classification_2024,
  author = {Your Name},
  title = {Article Classification using Web Scraping and Machine Learning},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/yourusername/article-classification}
}
```

---

## âš ï¸ Disclaimer

- Project ini dibuat untuk tujuan **edukasi dan penelitian**
- Web scraping harus mematuhi **Terms of Service** Springer
- Gunakan data scraping secara **etis dan bertanggung jawab**
- Tidak untuk keperluan komersial tanpa izin

---

## ğŸ“Š Project Statistics

- **Total Lines of Code**: ~500 lines
- **Total Cells**: 20+ cells
- **Dataset Size**: ~744 articles
- **Feature Dimensions**: ~10,000+ features
- **Models Trained**: 9 combinations
- **Development Time**: [Duration]

---

<div align="center">

### â­ Jika project ini bermanfaat, berikan **Star**! â­

**Made with â¤ï¸ and â˜• by the Article Classification Team**

[â¬† Back to Top](#article-classification-using-web-scraping--machine-learning-)

</div>
